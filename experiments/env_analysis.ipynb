{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "413ad4e7",
   "metadata": {},
   "source": [
    "# Environment Experiment Analysis\n",
    "\n",
    "Has analysis for a single environment's experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fa3ca7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from itertools import product\n",
    "import os\n",
    "import os.path as osp\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import tempfile\n",
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import posggym_agents\n",
    "\n",
    "import potmmcp.plot as plot_utils\n",
    "import potmmcp.plot.paper as paper_utils\n",
    "from potmmcp.config import BASE_REPO_DIR\n",
    "\n",
    "# import experiment parameters for each env\n",
    "sys.path.append(osp.join(BASE_REPO_DIR, \"experiments\"))\n",
    "import common\n",
    "import run_driving_exp as driving\n",
    "import run_pe_evader_exp as pe_evader\n",
    "import run_pe_pursuer_exp as pe_pursuer\n",
    "import run_pp2_exp as pp2\n",
    "import run_pp4_exp as pp4\n",
    "\n",
    "BASE_EXP_DIR = osp.join(BASE_REPO_DIR, \"experiments\")\n",
    "ENV_RESULTS_DIR = osp.join(BASE_EXP_DIR, \"results\")\n",
    "POSGGYM_AGENTS_DIR = osp.join(posggym_agents.config.BASE_DIR, 'agents')\n",
    "\n",
    "algname = \"POTMMCP\"\n",
    "baselinealgname = \"I-POMCP-PF\"\n",
    "\n",
    "SAVE_FIGURES = False\n",
    "SAVE_EXPECTED_RESULTS = True\n",
    "\n",
    "# uncomment the env to run analysis for \n",
    "# ENV_NAME = \"driving\"\n",
    "# ENV_NAME = \"pe_evader\"\n",
    "ENV_NAME = \"pe_pursuer\"\n",
    "# ENV_NAME = \"pp2\"\n",
    "# ENV_NAME = \"pp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class EnvInfo:\n",
    "    id: str\n",
    "    label: str\n",
    "    id_short: str\n",
    "    exp_params: common.EnvExperimentParams\n",
    "    policy_results_file: str\n",
    "    best_response_map: Dict[Tuple[str, ...], str]\n",
    "    policy_labels: Dict[Union[str, Tuple[str, ...]], str]\n",
    "    \n",
    "    @property\n",
    "    def results_dir(self) -> str:\n",
    "        return osp.join(ENV_RESULTS_DIR, self.id_short)\n",
    "    \n",
    "    @property\n",
    "    def figure_dir(self) -> str:\n",
    "        if SAVE_FIGURES:\n",
    "            return osp.join(self.results_dir, \"figures\")\n",
    "        return tempfile.gettempdir()\n",
    "    \n",
    "    @property\n",
    "    def baseline_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"baseline_experiment_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def baseline_avg_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"baseline_avg_performance_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def meta_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"meta_experiment_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def meta_avg_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"meta_avg_performance_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def lambda_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"lambda_experiment_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def lambda_avg_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"lambda_avg_performance_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def many_pi_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"many_pi_experiment_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def many_pi_avg_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"many_pi_avg_performance_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def sensitivity_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"sensitivity_experiment_results.csv\")\n",
    "    \n",
    "    @property\n",
    "    def sensitivity_avg_exp_results_file(self) -> str:\n",
    "        return osp.join(self.results_dir, \"sensitivity_avg_performance_results.csv\")\n",
    "        \n",
    "        \n",
    "        \n",
    "pe_policy_labels = {\n",
    "    \"klr_k0_seed0_i0-v0\": \"K0_0\",\n",
    "    \"klr_k1_seed0_i0-v0\": \"K1_0\",\n",
    "    \"klr_k2_seed0_i0-v0\": \"K2_0\",\n",
    "    \"klr_k3_seed0_i0-v0\": \"K3_0\",\n",
    "    \"klr_k4_seed0_i0-v0\": \"K4_0\",\n",
    "    \"klr_k0_seed0_i1-v0\": \"K0_1\",\n",
    "    \"klr_k1_seed0_i1-v0\": \"K1_1\",\n",
    "    \"klr_k2_seed0_i1-v0\": \"K2_1\",\n",
    "    \"klr_k3_seed0_i1-v0\": \"K3_1\",\n",
    "    \"klr_k4_seed0_i1-v0\": \"K4_1\",\n",
    "}\n",
    "\n",
    "for pi_id in list(pe_policy_labels):\n",
    "    pe_policy_labels[(pi_id,)] = pe_policy_labels[pi_id]\n",
    "\n",
    "\n",
    "# Analysis relevant info for each experiment environment\n",
    "env_info_map = {\n",
    "    \"driving\": EnvInfo(\n",
    "        id=driving.ENV_ID,\n",
    "        label=\"Driving\",\n",
    "        id_short=\"driving\",\n",
    "        exp_params=driving.DRIVING_EXP_PARAMS,\n",
    "        policy_results_file=osp.join(\n",
    "            POSGGYM_AGENTS_DIR, \"driving14x14wideroundabout_n2_v0\",  \"results\", \"klrbr_results.csv\"\n",
    "        ),\n",
    "        best_response_map = {\n",
    "            (\"klr_k0_seed0-v0\",): \"klr_k1_seed0-v0\",\n",
    "            (\"klr_k1_seed0-v0\",): \"klr_k2_seed0-v0\",\n",
    "            (\"klr_k2_seed0-v0\",): \"klr_k3_seed0-v0\",\n",
    "            (\"klr_k3_seed0-v0\",): \"klr_k4_seed0-v0\",\n",
    "            # K4 isn't added since it's not in policy prior, \n",
    "            # (\"klr_k4_seed0-v0\",): \"klr_k4_seed0-v0\",\n",
    "        },\n",
    "        policy_labels={\n",
    "            \"klr_k0_seed0-v0\": \"K0\",\n",
    "            \"klr_k1_seed0-v0\": \"K1\",\n",
    "            \"klr_k2_seed0-v0\": \"K2\",\n",
    "            \"klr_k3_seed0-v0\": \"K3\",\n",
    "            \"klr_k4_seed0-v0\": \"K4\",\n",
    "            (\"klr_k0_seed0-v0\",): \"K0\",\n",
    "            (\"klr_k1_seed0-v0\",): \"K1\",\n",
    "            (\"klr_k2_seed0-v0\",): \"K2\",\n",
    "            (\"klr_k3_seed0-v0\",): \"K3\",\n",
    "            (\"klr_k4_seed0-v0\",): \"K4\",\n",
    "        }\n",
    "    ),\n",
    "    \"pe_evader\": EnvInfo(\n",
    "        id=pe_evader.ENV_ID,\n",
    "        label=\"PE (Evader)\",\n",
    "        id_short=\"pe_evader\",\n",
    "        exp_params=pe_evader.PE_EVADER_EXP_PARAMS,\n",
    "        policy_results_file=osp.join(\n",
    "            POSGGYM_AGENTS_DIR, \"pursuitevasion16x16_v0\", \"results\", \"pairwise_results.csv\"\n",
    "        ),\n",
    "        best_response_map={\n",
    "            (\"klr_k0_seed0_i1-v0\",): \"klr_k1_seed0_i0-v0\",\n",
    "            (\"klr_k1_seed0_i1-v0\",): \"klr_k2_seed0_i0-v0\",\n",
    "            (\"klr_k2_seed0_i1-v0\",): \"klr_k3_seed0_i0-v0\",\n",
    "            (\"klr_k3_seed0_i1-v0\",): \"klr_k4_seed0_i0-v0\",\n",
    "            # \"klr_k4_seed0_i1-v0\": \"klr_k4_seed0_i0-v0\",\n",
    "        }, \n",
    "        policy_labels=pe_policy_labels\n",
    "    ),\n",
    "    \"pe_pursuer\": EnvInfo(\n",
    "        id=pe_pursuer.ENV_ID,\n",
    "        label=\"PE (Pursuer)\",\n",
    "        id_short=\"pe_pursuer\",\n",
    "        exp_params=pe_pursuer.PE_PURSUER_EXP_PARAMS,\n",
    "        policy_results_file=osp.join(\n",
    "            POSGGYM_AGENTS_DIR, \"pursuitevasion16x16_v0\", \"results\", \"pairwise_results.csv\"\n",
    "        ),\n",
    "        best_response_map={\n",
    "            (\"klr_k0_seed0_i0-v0\",): \"klr_k1_seed0_i1-v0\",\n",
    "            (\"klr_k1_seed0_i0-v0\",): \"klr_k2_seed0_i1-v0\",\n",
    "            (\"klr_k2_seed0_i0-v0\",): \"klr_k3_seed0_i1-v0\",\n",
    "            (\"klr_k3_seed0_i0-v0\",): \"klr_k4_seed0_i1-v0\",\n",
    "            # \"klr_k4_seed0_i0-v0\": \"klr_k4_seed0_i1-v0\",\n",
    "        },\n",
    "        policy_labels=pe_policy_labels\n",
    "    ),\n",
    "    \"pp2\": EnvInfo(\n",
    "        id=pp2.ENV_ID,\n",
    "        label=\"PP (two-agents)\",\n",
    "        id_short=\"pp2\",\n",
    "        exp_params=pp2.PP2_EXP_PARAMS,\n",
    "        policy_results_file=osp.join(\n",
    "            POSGGYM_AGENTS_DIR, \"predatorprey10x10_P2_p3_s2_coop_v0\", \"results\", \"pairwise_results.csv\"\n",
    "        ),\n",
    "        best_response_map={\n",
    "            ('sp_seed0-v0',): 'sp_seed0-v0',\n",
    "            ('sp_seed1-v0',): 'sp_seed1-v0',\n",
    "            ('sp_seed2-v0',): 'sp_seed2-v0',\n",
    "            ('sp_seed3-v0',): 'sp_seed3-v0',\n",
    "            ('sp_seed4-v0',): 'sp_seed4-v0',\n",
    "        },\n",
    "        policy_labels={\n",
    "            'sp_seed0-v0': \"S0\",\n",
    "            'sp_seed1-v0': \"S1\",\n",
    "            'sp_seed2-v0': \"S2\",\n",
    "            'sp_seed3-v0': \"S3\",\n",
    "            'sp_seed4-v0': \"S4\",\n",
    "            ('sp_seed0-v0',): \"S0\",\n",
    "            ('sp_seed1-v0',): \"S1\",\n",
    "            ('sp_seed2-v0',): \"S2\",\n",
    "            ('sp_seed3-v0',): \"S3\",\n",
    "            ('sp_seed4-v0',): \"S4\",\n",
    "        }\n",
    "    ),\n",
    "    \"pp4\": EnvInfo(\n",
    "        id=pp4.ENV_ID,\n",
    "        label=\"PP (four-agents)\",\n",
    "        id_short=\"pp4\",\n",
    "        exp_params=pp4.PP4_EXP_PARAMS,\n",
    "        policy_results_file=osp.join(\n",
    "            POSGGYM_AGENTS_DIR, \"predatorprey10x10_P4_p3_s3_coop_v0\", \"results\", \"pairwise_results.csv\"\n",
    "        ),\n",
    "        best_response_map={\n",
    "            ('sp_seed0-v0', 'sp_seed0-v0', 'sp_seed0-v0'): 'sp_seed0-v0',\n",
    "            ('sp_seed1-v0', 'sp_seed1-v0', 'sp_seed1-v0'): 'sp_seed1-v0',\n",
    "            ('sp_seed2-v0', 'sp_seed2-v0', 'sp_seed2-v0'): 'sp_seed2-v0',\n",
    "            ('sp_seed3-v0', 'sp_seed3-v0', 'sp_seed3-v0'): 'sp_seed3-v0',\n",
    "            ('sp_seed4-v0', 'sp_seed4-v0', 'sp_seed4-v0'): 'sp_seed4-v0',\n",
    "        },\n",
    "        policy_labels={\n",
    "            'sp_seed0-v0': \"S0\",\n",
    "            'sp_seed1-v0': \"S1\",\n",
    "            'sp_seed2-v0': \"S2\",\n",
    "            'sp_seed3-v0': \"S3\",\n",
    "            'sp_seed4-v0': \"S4\",\n",
    "            ('sp_seed0-v0', 'sp_seed0-v0', 'sp_seed0-v0'): \"T0\",\n",
    "            ('sp_seed1-v0', 'sp_seed1-v0', 'sp_seed1-v0'): \"T1\",\n",
    "            ('sp_seed2-v0', 'sp_seed2-v0', 'sp_seed2-v0'): \"T2\",\n",
    "            ('sp_seed3-v0', 'sp_seed3-v0', 'sp_seed3-v0'): \"T3\",\n",
    "            ('sp_seed4-v0', 'sp_seed4-v0', 'sp_seed4-v0'): \"T4\",\n",
    "        }\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "# ensure figure directory exists for each env\n",
    "for env_info in env_info_map.values():\n",
    "    os.makedirs(env_info.figure_dir, exist_ok=True)\n",
    "    \n",
    "env_info = env_info_map[ENV_NAME]\n",
    "\n",
    "print(f\"Running analysis for {ENV_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442ac69",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558efe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_df_info(df, display_columns: bool = True):\n",
    "    print(\"\\nDF info\")\n",
    "    print(\"-------\")\n",
    "    \n",
    "    for k in [\"agent_id\"]:\n",
    "        if k in df.columns:\n",
    "            values = df[k].unique().tolist()\n",
    "            values.sort()\n",
    "            print(f\"{k}: {values}\")\n",
    "    \n",
    "    if \"policy_id\" in df.columns:\n",
    "        policy_ids = df[\"policy_id\"].unique().tolist()\n",
    "        policy_ids.sort()\n",
    "        print(\"\\nPolicies\")\n",
    "        print(\"--------\")\n",
    "        for pi_id in policy_ids:\n",
    "            print(pi_id)\n",
    "    \n",
    "    if \"alg_id\" in df.columns:\n",
    "        alg_ids = df[\"alg_id\"].unique().tolist()\n",
    "        alg_ids.sort()\n",
    "        print(\"\\nAlg IDs\")\n",
    "        print(\"-------\")\n",
    "        for n in alg_ids:\n",
    "            print(n)\n",
    "    \n",
    "    if \"meta_pi\" in df.columns:\n",
    "        print(\"\\nMeta Pis:\")\n",
    "        print(\"---------\")\n",
    "        print(df[\"meta_pi\"].unique().tolist())\n",
    "    \n",
    "    if \"co_team_id\" in df.columns:\n",
    "        team_ids = df[\"co_team_id\"].unique().tolist()\n",
    "        team_ids.sort()\n",
    "        print(\"\\nCo-player Team IDs\")\n",
    "        print(\"------------------\")\n",
    "        for t_id in team_ids:\n",
    "            print(t_id)\n",
    "    \n",
    "    if \"co_team_seed\" in df.columns:\n",
    "        team_seeds = df[\"co_team_seed\"].unique().tolist()\n",
    "        team_seeds.sort()\n",
    "        print(\"\\nCo-player Team Seeds\")\n",
    "        print(\"--------------------\")\n",
    "        print(team_seeds)\n",
    "        \n",
    "    if \"num_episodes\" in df.columns:\n",
    "        num_eps = df[\"num_episodes\"].unique().tolist()\n",
    "        num_eps.sort()\n",
    "        print(\"\\nNum episodes\")\n",
    "        print(\"------------\")\n",
    "        print(num_eps)\n",
    "    \n",
    "    if display_columns:\n",
    "        print(\"\\nColumns\")\n",
    "        print(\"-------\")\n",
    "        for c in df.columns:\n",
    "            print(c)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadce3d2",
   "metadata": {},
   "source": [
    "## The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa737c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plot_utils.plot_environment(env_info.id, (9, 9))\n",
    "fig.savefig(osp.join(env_info.figure_dir, \"env.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331b738c",
   "metadata": {},
   "source": [
    "## Policy Prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20549991",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Policy Prior\")\n",
    "print(\"------------\")\n",
    "pprint(env_info.exp_params.get_policy_prior_map(remove_env_id=True))\n",
    "\n",
    "print(\"\\nPlanning agent policy ids\")\n",
    "print(\"-------------------------\")\n",
    "pprint(env_info.exp_params.get_planning_policy_ids(remove_env_id=True))\n",
    "\n",
    "print(\"\\nOther agent policy ids\")\n",
    "print(\"----------------------\")\n",
    "pprint(env_info.exp_params.get_other_policy_ids(remove_env_id=True))\n",
    "\n",
    "print(\"\\nAll policy ids\")\n",
    "print(\"----------------------\")\n",
    "pprint(env_info.exp_params.get_all_policy_ids(remove_env_id=True))\n",
    "\n",
    "print(\"\\nOther joint policies\")\n",
    "print(\"----------------------\")\n",
    "pprint(env_info.exp_params.get_other_joint_policies(remove_env_id=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db66886",
   "metadata": {},
   "source": [
    "## Loading Fixed Policy Data and add Full-Knowledge Best-Response baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eebf22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "policy_df = plot_utils.import_results(env_info.policy_results_file)\n",
    "\n",
    "all_fixed_policy_ids = policy_df[\"policy_id\"].unique().tolist()\n",
    "all_fixed_policy_ids.sort()\n",
    "print(\"All Policies\")\n",
    "print(\"------------\")\n",
    "for pi_id in all_fixed_policy_ids:\n",
    "    print(pi_id)\n",
    "# delete so it's not hanging around and polluting the namespace\n",
    "del all_fixed_policy_ids\n",
    "\n",
    "all_co_team_ids = policy_df[\"co_team_id\"].unique().tolist()\n",
    "all_co_team_ids.sort()\n",
    "print(\"\\nAll Co-Team IDs\")\n",
    "print(\"---------------\")\n",
    "for t_id in all_co_team_ids:\n",
    "    print(t_id)\n",
    "del all_co_team_ids\n",
    "    \n",
    "# Drop unneeded co-player policies\n",
    "policy_df = policy_df[policy_df[\"policy_id\"].isin(env_info.exp_params.get_all_policy_ids(remove_env_id=True))]\n",
    "policy_df = policy_df[policy_df[\"co_team_id\"].isin(env_info.exp_params.get_other_joint_policies(remove_env_id=True))]\n",
    "\n",
    "\n",
    "if env_info.exp_params.symmetric_env:\n",
    "    # for symmetric env we need to make sure there is a row for planning agent for all (policy_id, co_team_id)\n",
    "    # in asymmetric env, just drop rows for non-planning agent\n",
    "    next_exp_id = policy_df[\"exp_id\"].max() + 1\n",
    "    new_rows = []\n",
    "    for pi_id, co_team_id in product(policy_df[\"policy_id\"].unique(), policy_df[\"co_team_id\"].unique()):\n",
    "        pair_df = policy_df[(policy_df[\"policy_id\"] == pi_id) & (policy_df[\"co_team_id\"] == co_team_id)]\n",
    "        if len(pair_df) == 0:\n",
    "            print(f\"missing entry for ({pi_id}, {co_team_id}\")\n",
    "            continue\n",
    "        elif env_info.exp_params.planning_agent_id in pair_df[\"agent_id\"].unique():\n",
    "            # already in df with correct agent id\n",
    "            continue\n",
    "        # take first entry (there should only be one)\n",
    "        pair_row = policy_df.loc[\n",
    "            (policy_df[\"policy_id\"] == pi_id) & (policy_df[\"co_team_id\"] == co_team_id)\n",
    "        ].copy()\n",
    "        pair_row[\"agent_id\"] = env_info.exp_params.planning_agent_id\n",
    "        pair_row[\"exp_id\"] = next_exp_id\n",
    "        next_exp_id += 1\n",
    "        new_rows.append(pair_row)\n",
    "    \n",
    "    if len(new_rows):\n",
    "        print(f\"\\nAdding {len(new_rows)} rows for agent_id={env_info.exp_params.planning_agent_id}\")\n",
    "        new_pairs_df = pd.concat(new_rows, axis='rows').reset_index(drop=True)\n",
    "        policy_df = pd.concat([policy_df, new_pairs_df], ignore_index=True)\n",
    "        \n",
    "# Drop rows for non-planning agent\n",
    "policy_df = policy_df[policy_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "assert len(policy_df[\"agent_id\"].unique()) == 1\n",
    "\n",
    "\n",
    "# Add full-knowledge br\n",
    "new_rows = []\n",
    "next_exp_id = policy_df[\"exp_id\"].max() + 1\n",
    "for co_team_id, br_policy_id in env_info.best_response_map.items():\n",
    "    # Add BR agent row\n",
    "    br_row = policy_df.loc[\n",
    "        (policy_df[\"policy_id\"] == br_policy_id) \n",
    "        & (policy_df[\"co_team_id\"] == co_team_id)\n",
    "    ].copy()\n",
    "    # update policy id to baseline name\n",
    "    br_row[\"policy_id\"] = \"full-knowledge-br\"\n",
    "    br_row[\"exp_id\"] = next_exp_id\n",
    "    next_exp_id += 1\n",
    "    new_rows.append(br_row)\n",
    "    \n",
    "\n",
    "print(\"\\nStats from adding full-knowledge-br:\")\n",
    "print(f\"{len(policy_df)=}\")\n",
    "print(f\"{len(new_rows)=}\")\n",
    "br_df = pd.concat(new_rows, axis='rows').reset_index(drop=True)\n",
    "print(f\"{len(br_df)=}\")\n",
    "policy_df = pd.concat([policy_df, br_df], ignore_index=True)\n",
    "\n",
    "print(f\"{len(policy_df)=} (i.e. all together)\")\n",
    "policy_df[policy_df[\"policy_id\"] == \"full-knowledge-br\"]\n",
    "\n",
    "display_df_info(policy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a961bf3a",
   "metadata": {},
   "source": [
    "## Fixed policies pairwise performance\n",
    "\n",
    "This is what was used to generate the meta-policies.\n",
    "\n",
    "Here we show pairwise performance between each individual policy and co-team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b73786",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plot_utils.plot_pairwise_comparison(\n",
    "    policy_df[policy_df[\"policy_id\"] != \"full-knowledge-br\"],\n",
    "    y_key=\"episode_return_mean\", \n",
    "    policy_key=\"policy_id\",\n",
    "    coplayer_policy_key=\"co_team_id\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    vrange=None, \n",
    "    figsize=(3, 6), \n",
    "    valfmt=\"{x:.2f}\",\n",
    "    policies=None,\n",
    "    coplayer_policies=None,\n",
    "    policy_labels=env_info.policy_labels,\n",
    "    average_duplicates=True,\n",
    "    duplicate_warning=True\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig.savefig(osp.join(env_info.figure_dir, \"fixed_policy_payoffs.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c2638",
   "metadata": {},
   "source": [
    "## Loading BAPOSGMCP Data and Combining with Fixed-Policy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300963e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def combine_dfs(df1, df2):\n",
    "    # First need to update exp_ids of one dataframe so there are no duplicate exp_ids\n",
    "    df1_max_exp_id = df1[\"exp_id\"].max()\n",
    "    if df2[\"exp_id\"].min() <= df1_max_exp_id:\n",
    "        df2[\"exp_id\"] += df1_max_exp_id+1\n",
    "\n",
    "    combined_df = pd.concat([df1, df2]).reset_index(drop = True)\n",
    "\n",
    "    def add_alg_id(row):\n",
    "        pi_id = row[\"policy_id\"]\n",
    "        if pi_id.startswith(\"klr\") or pi_id.startswith(\"sp\"):\n",
    "            return \"fixed\"\n",
    "        tokens = pi_id.split(\"_\")\n",
    "        alg_id = \"_\".join([\n",
    "            t for t in tokens \n",
    "            if all(\n",
    "                s not in t for s in [\n",
    "                    \"actionselection\", \n",
    "                    \"searchtimelimit\",\n",
    "                    \"numsims\", \n",
    "                    \"truncated\", \n",
    "                    \"greedy\", \n",
    "                    \"softmax\", \n",
    "                    \"uniform\", \n",
    "                    \"piklr\",\n",
    "                    \"pisp\",\n",
    "                    \"i0\",\n",
    "                    \"i1\"\n",
    "                ]\n",
    "            )\n",
    "        ])\n",
    "        return alg_id\n",
    "\n",
    "\n",
    "    def add_meta_pi(row):\n",
    "        pi_id = row[\"policy_id\"]\n",
    "        for meta_pi in [\"greedy\", \"softmax\", \"uniform\"]:\n",
    "            if meta_pi in pi_id:\n",
    "                return meta_pi\n",
    "        return \"NA\"\n",
    "\n",
    "    combined_df[\"alg_id\"] = combined_df.apply(add_alg_id, axis=1)\n",
    "    combined_df[\"meta_pi\"] = combined_df.apply(add_meta_pi, axis=1)\n",
    "        \n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad8cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_df = plot_utils.import_results(env_info.baseline_exp_results_file)\n",
    "\n",
    "# drop non-planning agent rows\n",
    "baseline_df = baseline_df[baseline_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "\n",
    "baseline_df = combine_dfs(baseline_df, policy_df)\n",
    "display_df_info(baseline_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee9ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = plot_utils.import_results(env_info.meta_exp_results_file)\n",
    "\n",
    "# drop non-planning agent rows\n",
    "meta_df = meta_df[meta_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "\n",
    "meta_df = combine_dfs(meta_df, policy_df)\n",
    "display_df_info(meta_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbc66bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_df = plot_utils.import_results(env_info.lambda_exp_results_file)\n",
    "\n",
    "# drop non-planning agent rows\n",
    "lambda_df = lambda_df[lambda_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "\n",
    "display_df_info(lambda_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547c101",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    env_info.exp_params.many_pi_pairwise_returns is not None\n",
    "    and osp.exists(env_info.many_pi_exp_results_file)\n",
    "):\n",
    "    many_pi_df = plot_utils.import_results(env_info.many_pi_exp_results_file)\n",
    "\n",
    "    # drop non-planning agent rows\n",
    "    many_pi_df = many_pi_df[many_pi_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "\n",
    "    # Add Full-knowledge BR\n",
    "    many_pi_pairwise_returns = env_info.exp_params.many_pi_pairwise_returns\n",
    "    br_returns = {}\n",
    "    for pi_state, policy_returns in many_pi_pairwise_returns.items():\n",
    "        max_policies = []\n",
    "        max_return = -float(\"inf\")\n",
    "        for pi_id, ret in policy_returns.items():\n",
    "            if ret > max_return:\n",
    "                max_return = ret\n",
    "                max_policies = [pi_id]\n",
    "            elif ret == max_return:\n",
    "                max_policies.append(pi_id)\n",
    "\n",
    "        br_returns[pi_state] = max_return\n",
    "\n",
    "    mean_br_value = sum(br_returns.values()) / len(br_returns)\n",
    "\n",
    "    # Add BR row to df\n",
    "    # We will only be using episode returns in analysis so we just copy any row\n",
    "    br_row = many_pi_df.loc[[0], :].copy(deep=True)\n",
    "    br_row[\"policy_id\"] = \"full-knowledge-br\"\n",
    "    br_row[f\"coplayer_policy_id_{env_info.exp_params.planning_agent_id}\"] = \"full-knowledge-br\"\n",
    "    br_row[\"episode_return_mean\"] = mean_br_value\n",
    "    br_row[\"episode_return_CI\"] = 0.0\n",
    "    br_row[\"exp_id\"] = many_pi_df[\"exp_id\"].max() + 1\n",
    "\n",
    "    many_pi_df = pd.concat([many_pi_df, br_row], ignore_index=True)\n",
    "\n",
    "    display_df_info(many_pi_df)\n",
    "else:\n",
    "    # exp not run for current env \n",
    "    many_pi_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805d5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    env_info.exp_params.sensitivity_pairwise_returns is not None\n",
    "    and osp.exists(env_info.sensitivity_exp_results_file)\n",
    "):\n",
    "    sens_df = plot_utils.import_results(env_info.sensitivity_exp_results_file)\n",
    "\n",
    "    # drop non-planning agent rows\n",
    "    sens_df = sens_df[sens_df[\"agent_id\"] == env_info.exp_params.planning_agent_id]\n",
    "    \n",
    "    # Add Full-knowledge BR\n",
    "    sens_pairwise_returns = env_info.exp_params.sensitivity_pairwise_returns\n",
    "    br_returns = {}\n",
    "    for pi_state, policy_returns in sens_pairwise_returns.items():\n",
    "        max_policies = []\n",
    "        max_return = -float(\"inf\")\n",
    "        for pi_id, ret in policy_returns.items():\n",
    "            if ret > max_return:\n",
    "                max_return = ret\n",
    "                max_policies = [pi_id]\n",
    "            elif ret == max_return:\n",
    "                max_policies.append(pi_id)\n",
    "\n",
    "        br_returns[pi_state] = max_return\n",
    "\n",
    "    mean_br_value = sum(br_returns.values()) / len(br_returns)\n",
    "\n",
    "    # Add BR row to df\n",
    "    # We will only be using episode returns in analysis so we just copy any row\n",
    "    br_row = sens_df.iloc[[0], :].copy(deep=True)\n",
    "    br_row[\"policy_id\"] = \"full-knowledge-br\"\n",
    "    br_row[f\"coplayer_policy_id_{env_info.exp_params.planning_agent_id}\"] = \"full-knowledge-br\"\n",
    "    br_row[\"episode_return_mean\"] = mean_br_value\n",
    "    br_row[\"episode_return_CI\"] = 0.0\n",
    "    br_row[\"exp_id\"] = sens_df[\"exp_id\"].max() + 1\n",
    "\n",
    "    sens_df = pd.concat([sens_df, br_row], ignore_index=True)\n",
    "\n",
    "    display_df_info(sens_df)\n",
    "else:\n",
    "    # exp not run for current env \n",
    "    sens_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e545c59",
   "metadata": {},
   "source": [
    "## Pairwise performance\n",
    "\n",
    "Here we look at the performance of each policy against each other policy including BAPOSGMCP and baselines with different number of simulations, action selection, and meta-policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f6971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_utils.plot_pairwise_comparison(\n",
    "    baseline_df,\n",
    "    y_key=\"episode_return_mean\", \n",
    "    policy_key=\"policy_id\",\n",
    "    y_err_key=None,\n",
    "    coplayer_policy_key=\"co_team_id\",\n",
    "    vrange=None, \n",
    "    figsize=(20, len(baseline_df[\"policy_id\"].unique())), \n",
    "    valfmt=\"{x:.2f}\",\n",
    "    policies=None,\n",
    "    coplayer_policies=None,\n",
    "    policy_labels=env_info.policy_labels,\n",
    "    average_duplicates=True,\n",
    "    duplicate_warning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49f7bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_utils.plot_pairwise_comparison(\n",
    "    baseline_df,\n",
    "    # lambda_df,\n",
    "    y_key=\"num_episodes\",\n",
    "    policy_key=\"policy_id\",\n",
    "    y_err_key=None,\n",
    "    coplayer_policy_key=\"co_team_id\",\n",
    "    vrange=None, \n",
    "    figsize=(20, len(baseline_df[\"policy_id\"].unique())), \n",
    "    valfmt=\"{x:.0f}\",\n",
    "    policies=None,\n",
    "    coplayer_policies=None,\n",
    "    policy_labels=env_info.policy_labels,\n",
    "    average_duplicates=True,\n",
    "    duplicate_warning=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fe7ed2",
   "metadata": {},
   "source": [
    "# Expected Performance\n",
    "\n",
    "Here we look at the expected performance given the policy prior of BAPOSGMCP and the different baselines.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "1. Comparing different meta-policies\n",
    "2. Comparing performance using meta-policy vs using a single fixed policy\n",
    "3. Comparing performance between all algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52d3fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "baseline_exp_df = plot_utils.get_uniform_expected_df(\n",
    "    baseline_df, \n",
    "    coplayer_policies=env_info.exp_params.get_other_joint_policies(remove_env_id=True),\n",
    "    coplayer_policy_key=\"co_team_id\"\n",
    ")\n",
    "display_df_info(baseline_exp_df, display_columns=False)\n",
    "if SAVE_EXPECTED_RESULTS:\n",
    "    baseline_exp_df.to_csv(env_info.baseline_avg_exp_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786c8d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_exp_df = plot_utils.get_uniform_expected_df(\n",
    "    meta_df, \n",
    "    coplayer_policies=env_info.exp_params.get_other_joint_policies(remove_env_id=True),\n",
    "    coplayer_policy_key=\"co_team_id\"\n",
    ")\n",
    "display_df_info(meta_exp_df, display_columns=False)\n",
    "if SAVE_EXPECTED_RESULTS:\n",
    "    meta_exp_df.to_csv(env_info.meta_avg_exp_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8a8204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lambda_exp_df = plot_utils.get_uniform_expected_df(\n",
    "    lambda_df, \n",
    "    coplayer_policies=env_info.exp_params.get_other_joint_policies(remove_env_id=True),\n",
    "    coplayer_policy_key=\"co_team_id\"\n",
    ")\n",
    "display_df_info(lambda_exp_df, display_columns=False)\n",
    "if SAVE_EXPECTED_RESULTS:\n",
    "    lambda_exp_df.to_csv(env_info.lambda_avg_exp_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b4ab9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if many_pi_df is not None:\n",
    "    # Many pi df already averaged, need to save to include Full-Knowledge BR though\n",
    "    display_df_info(many_pi_df, display_columns=False)\n",
    "    if SAVE_EXPECTED_RESULTS:\n",
    "        many_pi_df.to_csv(env_info.many_pi_avg_exp_results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d145d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if sens_df is not None:\n",
    "    # Sensitivity df already averaged, need to save to include Full-Knowledge BR though\n",
    "    display_df_info(sens_df, display_columns=False)\n",
    "    if SAVE_EXPECTED_RESULTS:\n",
    "        sens_df.to_csv(env_info.sensitivity_avg_exp_results_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c212d16",
   "metadata": {},
   "source": [
    "## Comparison of the different Meta-Policies\n",
    "\n",
    "Here we look at the performance of our algorithm using the difference meta-policies.\n",
    "\n",
    "Looking at performance with:\n",
    "\n",
    "- truncated search\n",
    "- using PUCB\n",
    "\n",
    "We also look at the performance of the metabaseline with the different meta-policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09e14f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_pi_label_map = {\n",
    "    \"greedy\": r\"$\\sigma^{G}$\",\n",
    "    \"softmax\": r\"$\\sigma^{S}$\",\n",
    "    \"uniform\": r\"$\\sigma^{U}$\",\n",
    "}\n",
    "\n",
    "potmmcp_meta_exp_df = meta_exp_df[\n",
    "    (meta_exp_df[\"alg_id\"].isin([\"baposgmcp\"])) & (meta_exp_df[\"truncated\"] == True)\n",
    "]\n",
    "\n",
    "display_df_info(potmmcp_meta_exp_df, display_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9078931b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_COL_WIDTH, 3.8)}\n",
    "subplot_kwargs = {\n",
    "    \"ylabel\": \"Mean Episode Return\",\n",
    "    \"xlabel\": \"Search time (s)\"\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "paper_utils.plot_meta_policy_performance(\n",
    "    potmmcp_meta_exp_df,\n",
    "    ax,\n",
    "    x_key=\"search_time_limit\",\n",
    "    y_key=\"episode_return_mean\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    meta_pi_label_map=meta_pi_label_map,\n",
    ")\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=3, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.12, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, f\"meta_pi_return.png\"))\n",
    "\n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cf661",
   "metadata": {},
   "source": [
    "## Comparing Meta-Policy versus using a single policy\n",
    "\n",
    "Here we look at the performance of POTMMCP with a meta-policy against not using a meta-policy (i.e. using the different fixed policies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc157ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "meta_vs_single_label_map = {\n",
    "    \"baposgmcp_metasoftmax\": r\"$\\sigma^{S}$\",\n",
    "    \"baposgmcp-random\": \"Random\",\n",
    "    \"baposgmcp-random_i0\": \"Random\",\n",
    "    \"baposgmcp-random_i1\": \"Random\",\n",
    "    \"baposgmcp-fixed_piklrk0seed0-v0\": \"K0\", \n",
    "    \"baposgmcp-fixed_piklrk1seed0-v0\": \"K1\", \n",
    "    \"baposgmcp-fixed_piklrk2seed0-v0\": \"K2\",\n",
    "    \"baposgmcp-fixed_piklrk3seed0-v0\": \"K3\",\n",
    "    \"baposgmcp-fixed_piklrk4seed0-v0\": \"K4\",\n",
    "    \"baposgmcp-fixed_pispseed0-v0\": \"S0\",\n",
    "    \"baposgmcp-fixed_pispseed1-v0\": \"S1\",\n",
    "    \"baposgmcp-fixed_pispseed2-v0\": \"S2\",\n",
    "    \"baposgmcp-fixed_pispseed3-v0\": \"S3\",\n",
    "    \"baposgmcp-fixed_pispseed4-v0\": \"S4\",\n",
    "    \"baposgmcp-fixed_i0_piklrk0seed0i0-v0\": \"K0_0\",\n",
    "    \"baposgmcp-fixed_i0_piklrk1seed0i0-v0\": \"K1_0\",\n",
    "    \"baposgmcp-fixed_i0_piklrk2seed0i0-v0\": \"K2_0\",\n",
    "    \"baposgmcp-fixed_i0_piklrk3seed0i0-v0\": \"K3_0\",\n",
    "    \"baposgmcp-fixed_i0_piklrk4seed0i0-v0\": \"K4_0\",\n",
    "    \"baposgmcp-fixed_i1_piklrk0seed0i1-v0\": \"K0_1\",\n",
    "    \"baposgmcp-fixed_i1_piklrk1seed0i1-v0\": \"K1_1\",\n",
    "    \"baposgmcp-fixed_i1_piklrk2seed0i1-v0\": \"K2_1\",\n",
    "    \"baposgmcp-fixed_i1_piklrk3seed0i1-v0\": \"K3_1\",\n",
    "    \"baposgmcp-fixed_i1_piklrk4seed0i1-v0\": \"K4_1\",\n",
    "}\n",
    "\n",
    "meta_vs_single_df = meta_exp_df[\n",
    "    (meta_exp_df[\"alg_id\"].isin([\"baposgmcp\", \"baposgmcp-fixed\", \"baposgmcp-random\"]))\n",
    "    & (meta_exp_df[\"action_selection\"].isin([\"pucb\"]))\n",
    "    & (meta_exp_df[\"meta_pi\"].isin([\"softmax\", \"NA\"]))\n",
    "    & (\n",
    "        ((meta_exp_df[\"alg_id\"] == \"baposgmcp-random\") & (meta_exp_df[\"truncated\"] == False))\n",
    "        | ((meta_exp_df[\"alg_id\"].isin([\"baposgmcp\", \"baposgmcp-fixed\"])) & (meta_exp_df[\"truncated\"] == True))\n",
    "    )\n",
    "]\n",
    "display_df_info(meta_vs_single_df, display_columns=False)\n",
    "\n",
    "policy_prefixes = set()\n",
    "for pi_id in meta_vs_single_df[\"policy_id\"].unique():\n",
    "    tokens = pi_id.split(\"_\")\n",
    "    if tokens[0] == \"baposgmcp-fixed\":\n",
    "        if \"_i0\" in pi_id or \"_i1\" in pi_id:\n",
    "            prefix = \"_\".join(tokens[:3])\n",
    "        else:\n",
    "            prefix = \"_\".join(tokens[:2])\n",
    "        policy_prefixes.add(prefix)\n",
    "        \n",
    "policy_prefixes = list(policy_prefixes)\n",
    "policy_prefixes.sort()\n",
    "# add this way so order in figure is correct\n",
    "policy_prefixes.insert(0, \"baposgmcp-random\")\n",
    "policy_prefixes.insert(0, \"baposgmcp_metasoftmax\")\n",
    "print(\"\\nPolicy Prefixes:\")\n",
    "pprint(policy_prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ae189",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_COL_WIDTH, 3.8)}\n",
    "subplot_kwargs = {\n",
    "    \"ylabel\": \"Mean Episode Return\",\n",
    "    \"xlabel\": \"Search time (s)\"\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "paper_utils.plot_performance(\n",
    "    meta_vs_single_df,\n",
    "    ax=ax,\n",
    "    x_key=\"search_time_limit\",\n",
    "    y_key=\"episode_return_mean\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    policy_key=\"policy_id\",\n",
    "    policy_prefixes=policy_prefixes,\n",
    "    constant_policy_prefixes=[],\n",
    "    pi_label_map=meta_vs_single_label_map,\n",
    ")\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=2, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.35, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, f\"meta_vs_fixed_return.png\"))\n",
    "\n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93b43dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta_vs_single_best_worst_pi_env_label_maps = {\n",
    "    \"driving\": {\n",
    "        \"baposgmcp-fixed_piklrk0seed0-v0\": \"Worst\", \n",
    "        # \"baposgmcp-fixed_piklrk1seed0-v0\": \"K1\", \n",
    "        \"baposgmcp-fixed_piklrk2seed0-v0\": \"Best\",\n",
    "        # \"baposgmcp-fixed_piklrk3seed0-v0\": \"K3\",\n",
    "        # \"baposgmcp-fixed_piklrk4seed0-v0\": \"K4\"\n",
    "    },\n",
    "    \"pe_evader\": {\n",
    "        \"baposgmcp-fixed_i0_piklrk0seed0i0-v0\": \"Worst\",\n",
    "        #\"baposgmcp-fixed_i0_piklrk1seed0i0-v0\": \"K1_0\",\n",
    "        \"baposgmcp-fixed_i0_piklrk2seed0i0-v0\": \"Best\",\n",
    "        # \"baposgmcp-fixed_i0_piklrk3seed0i0-v0\": \"K3_0\",\n",
    "        # \"baposgmcp-fixed_i0_piklrk4seed0i0-v0\": \"K4_0\"\n",
    "    },\n",
    "    \"pe_pursuer\": {\n",
    "        \"baposgmcp-fixed_i1_piklrk0seed0i1-v0\": \"Worst\",\n",
    "        # \"baposgmcp-fixed_i1_piklrk1seed0i1-v0\": \"K1_1\",\n",
    "        \"baposgmcp-fixed_i1_piklrk2seed0i1-v0\": \"Best\",\n",
    "        # \"baposgmcp-fixed_i1_piklrk3seed0i1-v0\": \"K3_1\",\n",
    "        # \"baposgmcp-fixed_i1_piklrk4seed0i1-v0\": \"K4_1\"\n",
    "    },\n",
    "    \"pp2\": {\n",
    "        # \"baposgmcp_fixed_pispseed0-v0\": \"S0\",\n",
    "        \"baposgmcp-fixed_pispseed1-v0\": \"Worst\",\n",
    "        # \"baposgmcp_fixed_pispseed2-v0\": \"S2\",\n",
    "        # \"baposgmcp_fixed_pispseed3-v0\": \"S3\",\n",
    "        \"baposgmcp-fixed_pispseed4-v0\": \"Best\",\n",
    "    },\n",
    "    \"pp4\": {\n",
    "        \"baposgmcp-fixed_pispseed0-v0\": \"Worst\", \n",
    "        \"baposgmcp-fixed_pispseed1-v0\": \"Best\", \n",
    "        # \"baposgmcp-fixed_pispseed2-v0\": \"S2\",\n",
    "        # \"baposgmcp-fixed_pispseed3-v0\": \"S3\",\n",
    "        # \"baposgmcp-fixed_pispseed4-v0\": \"S4\"\n",
    "    }\n",
    "}\n",
    "\n",
    "meta_vs_single_best_worst_pi_label_map = {\n",
    "    \"baposgmcp_metasoftmax\": r\"$\\sigma^{S}$\",\n",
    "    \"baposgmcp-random\": \"Random\",\n",
    "}\n",
    "meta_vs_single_best_worst_pi_label_map.update(meta_vs_single_best_worst_pi_env_label_maps[env_info.id_short])\n",
    "\n",
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_COL_WIDTH, 3.8)}\n",
    "subplot_kwargs = {\n",
    "    \"ylabel\": \"Mean Episode Return\",\n",
    "    \"xlabel\": \"Search time (s)\"\n",
    "}\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 1\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=num_rows,\n",
    "    ncols=num_cols,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "paper_utils.plot_performance(\n",
    "    meta_vs_single_df,\n",
    "    ax=ax,\n",
    "    x_key=\"search_time_limit\",\n",
    "    y_key=\"episode_return_mean\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    policy_key=\"policy_id\",\n",
    "    policy_prefixes=list(meta_vs_single_best_worst_pi_label_map),\n",
    "    constant_policy_prefixes=[],\n",
    "    pi_label_map=meta_vs_single_best_worst_pi_label_map,\n",
    ")\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=2, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.2, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, f\"meta_vs_fixed_return_best_and_worst.png\"))\n",
    "\n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1dcf24",
   "metadata": {},
   "source": [
    "## Comparing BAPOSGMCP versus baselines\n",
    "\n",
    "Finally we compare BAPOSGMCP versus baselines. Specifically we compare:\n",
    "\n",
    "- BAPOSGMCP (PUCB + Best Meta)\n",
    "- IPOMCP-Meta (UCB + Best Meta)\n",
    "- IPOMCP (UCB + Random)\n",
    "- Full Knowledge BR\n",
    "- Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24acbbd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_meta_pi = \"softmax\"\n",
    "baseline_perf_df = baseline_exp_df[\n",
    "    (baseline_exp_df[\"alg_id\"] == \"full-knowledge-br\")\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"metabaseline\") & (baseline_exp_df[\"meta_pi\"] == best_meta_pi))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"baposgmcp\") & (baseline_exp_df[\"meta_pi\"] == best_meta_pi) & (baseline_exp_df[\"truncated\"] == True))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"baposgmcp-random\") & (baseline_exp_df[\"truncated\"] == False))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"ucbmcp\") & (baseline_exp_df[\"meta_pi\"] == best_meta_pi) & (baseline_exp_df[\"truncated\"] == True))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"ucbmcp-random\") & (baseline_exp_df[\"truncated\"] == False))\n",
    "]\n",
    "\n",
    "baseline_policy_prefixes_to_plot = [\n",
    "    f\"baposgmcp_meta{best_meta_pi}\",\n",
    "    # \"baposgmcp-random\",\n",
    "    \"ucbmcp-random\",\n",
    "    f\"ucbmcp_meta{best_meta_pi}\",\n",
    "    f\"metabaseline_{best_meta_pi}\",\n",
    "    f\"full-knowledge-br\",\n",
    "]\n",
    "baseline_constant_policy_prefixes = [\n",
    "    f\"metabaseline_{best_meta_pi}\",\n",
    "    f\"full-knowledge-br\",\n",
    "]\n",
    "\n",
    "baseline_pi_label_map = {\n",
    "    f\"baposgmcp_meta{best_meta_pi}\": algname,\n",
    "    # \"baposgmcp-random\": f\"{algname} + Random\", \n",
    "    \"full-knowledge-br\": \"Best-Response\",\n",
    "    f\"metabaseline_{best_meta_pi}\": \"Meta-Policy\",\n",
    "    f\"ucbmcp_meta{best_meta_pi}\": f\"{baselinealgname} + Meta\",\n",
    "    \"ucbmcp-random\": f\"{baselinealgname} + Random\"\n",
    "}\n",
    "\n",
    "display_df_info(baseline_perf_df, display_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e47ddb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_WIDTH, 6)}\n",
    "subplot_kwargs = {\n",
    "    \"ylabel\": \"Mean Episode Return\",\n",
    "    \"xlabel\": \"Search time (s)\"\n",
    "}\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 1\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=num_rows,\n",
    "    ncols=num_cols,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "paper_utils.plot_performance(\n",
    "    baseline_perf_df,\n",
    "    ax=ax,\n",
    "    x_key=\"search_time_limit\",\n",
    "    y_key=\"episode_return_mean\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    policy_key=\"policy_id\",\n",
    "    policy_prefixes=baseline_policy_prefixes_to_plot,\n",
    "    constant_policy_prefixes=baseline_constant_policy_prefixes,\n",
    "    pi_label_map=baseline_pi_label_map,\n",
    ")\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=3, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.12, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, \"baselines_return_vs_search_time.png\"))\n",
    "\n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50e34d",
   "metadata": {},
   "source": [
    "## Comparing POTMMCP using different lambda values\n",
    "\n",
    "Here we look at POTMMCP using different values of the lambda hyperparameter, which controls the weighting of the policy prior during PUCT action selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cd11b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_WIDTH, 6)}\n",
    "subplot_kwargs = {\n",
    "    \"ylabel\": \"Mean Episode Return\",\n",
    "    \"xlabel\": \"Search time (s)\"\n",
    "}\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 1\n",
    "\n",
    "fig, ax = plt.subplots(\n",
    "    nrows=num_rows,\n",
    "    ncols=num_cols,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "paper_utils.plot_lambda_performance(\n",
    "    lambda_exp_df,\n",
    "    ax=ax,\n",
    "    x_key=\"search_time_limit\",\n",
    "    y_key=\"episode_return_mean\",\n",
    "    y_err_key=\"episode_return_CI\",\n",
    "    lambda_key=\"root_exploration_fraction\"\n",
    ")\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=4, loc=\"lower right\")\n",
    "\n",
    "fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.08, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, \"lambdas_return_vs_search_time.png\"))\n",
    "\n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5d93c9",
   "metadata": {},
   "source": [
    "## Comparing POTMMCP with large policy set\n",
    "\n",
    "Here we look at POTMMCP when the policy set is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab054baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if many_pi_df is not None:\n",
    "    # only supported for some envs\n",
    "    fig_kwargs = {\"figsize\": (paper_utils.PAGE_WIDTH, 6)}\n",
    "    subplot_kwargs = {\n",
    "        \"ylabel\": \"Mean Episode Return\",\n",
    "        \"xlabel\": \"Search time (s)\"\n",
    "    }\n",
    "\n",
    "    num_rows = 1\n",
    "    num_cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=num_rows,\n",
    "        ncols=num_cols,\n",
    "        squeeze=True,\n",
    "        subplot_kw=subplot_kwargs,\n",
    "        **fig_kwargs,\n",
    "    )\n",
    "\n",
    "    many_pi_policy_prefixes_to_plot = [\n",
    "        #\"potmmcp_metagreedy\",\n",
    "        \"potmmcp_metasoftmax\",\n",
    "        # \"potmmcp_metauniform\",\n",
    "        # \"baposgmcp-random\",\n",
    "        # \"metabaseline_greedy\",\n",
    "        \"metabaseline_softmax\",\n",
    "        #\"metabaseline_uniform\",\n",
    "        \"full-knowledge-br\",\n",
    "    ]\n",
    "\n",
    "\n",
    "    many_pi_constant_policy_prefixes = [\n",
    "        # \"metabaseline_greedy\",\n",
    "        \"metabaseline_softmax\",\n",
    "        # \"metabaseline_uniform\"\n",
    "        \"full-knowledge-br\",\n",
    "    ]\n",
    "\n",
    "    many_pi_pi_label_map = {\n",
    "        \"potmmcp_metagreedy\": f\"{algname} Greedy\",\n",
    "        \"potmmcp_metasoftmax\": f\"{algname}\",\n",
    "        \"potmmcp_metauniform\": f\"{algname} Uniform\",\n",
    "        \"full-knowledge-br\": \"Best-Response\",\n",
    "        \"metabaseline_greedy\": \"Meta-Policy Greedy\",\n",
    "        \"metabaseline_softmax\": \"Meta-Policy\",\n",
    "        \"metabaseline_uniform\": \"Meta-Policy Uniform\",\n",
    "    }\n",
    "\n",
    "    paper_utils.plot_performance(\n",
    "        many_pi_df,\n",
    "        ax=ax,\n",
    "        x_key=\"search_time_limit\",\n",
    "        y_key=\"episode_return_mean\",\n",
    "        y_err_key=\"episode_return_CI\",\n",
    "        policy_key=\"policy_id\",\n",
    "        policy_prefixes=many_pi_policy_prefixes_to_plot,\n",
    "        constant_policy_prefixes=many_pi_constant_policy_prefixes,\n",
    "        pi_label_map=many_pi_pi_label_map,\n",
    "    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, ncol=3, loc=\"lower right\")\n",
    "\n",
    "    fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.08, 1.0, 1.0))\n",
    "    fig.savefig(osp.join(env_info.figure_dir, \"many_pi_return_vs_search_time.png\"))\n",
    "\n",
    "    del fig_kwargs\n",
    "    del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6d6e96",
   "metadata": {},
   "source": [
    "## Sensitivity of POTMMCP to out of distribution policies\n",
    "\n",
    "Here we look at POTMMCP when the policies in the internal policy set are different to the actual policies used by the other agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348865a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sens_df is not None:\n",
    "    # only supported for some envs\n",
    "    fig_kwargs = {\"figsize\": (paper_utils.PAGE_WIDTH, 6)}\n",
    "    subplot_kwargs = {\n",
    "        \"ylabel\": \"Mean Episode Return\",\n",
    "        \"xlabel\": \"Search time (s)\"\n",
    "    }\n",
    "\n",
    "    num_rows = 1\n",
    "    num_cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=num_rows,\n",
    "        ncols=num_cols,\n",
    "        squeeze=True,\n",
    "        subplot_kw=subplot_kwargs,\n",
    "        **fig_kwargs,\n",
    "    )\n",
    "    \n",
    "    best_meta_pi = \"softmax\"\n",
    "\n",
    "    sens_policy_prefixes_to_plot = [\n",
    "        f\"potmmcp_meta{best_meta_pi}\",\n",
    "        f\"ucbmcp_meta{best_meta_pi}\",\n",
    "        \"ucbmcp-random\",\n",
    "        f\"metabaseline_{best_meta_pi}\",\n",
    "        \"full-knowledge-br\",\n",
    "    ]\n",
    "\n",
    "    sens_constant_policy_prefixes = [\n",
    "        f\"metabaseline_{best_meta_pi}\",\n",
    "        \"full-knowledge-br\",\n",
    "    ]\n",
    "\n",
    "    sens_pi_label_map = {\n",
    "        f\"potmmcp_meta{best_meta_pi}\": f\"{algname}\",\n",
    "        \"full-knowledge-br\": \"Best-Response\",\n",
    "        \"metabaseline_softmax\": \"Meta-Policy\",\n",
    "        f\"ucbmcp_meta{best_meta_pi}\": f\"{baselinealgname} + Meta\",\n",
    "        \"ucbmcp-random\": f\"{baselinealgname} + Random\"\n",
    "    }\n",
    "\n",
    "    paper_utils.plot_performance(\n",
    "        sens_df,\n",
    "        ax=ax,\n",
    "        x_key=\"search_time_limit\",\n",
    "        y_key=\"episode_return_mean\",\n",
    "        y_err_key=\"episode_return_CI\",\n",
    "        policy_key=\"policy_id\",\n",
    "        policy_prefixes=sens_policy_prefixes_to_plot,\n",
    "        constant_policy_prefixes=sens_constant_policy_prefixes,\n",
    "        pi_label_map=sens_pi_label_map,\n",
    "    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, ncol=3, loc=\"lower right\")\n",
    "\n",
    "    fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.16, 1.0, 1.0))\n",
    "    fig.savefig(osp.join(env_info.figure_dir, \"sensitivity_return_vs_search_time.png\"))\n",
    "\n",
    "    del fig_kwargs\n",
    "    del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a392977",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Here we take a deeper dive into the characteristics of POTMMCP. Specifically looking at:\n",
    "\n",
    "1. Belief accuracy\n",
    "2. Planning time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edad117",
   "metadata": {},
   "source": [
    "## Looking at Belief accuracy by steps\n",
    "\n",
    "- action_dist_distance\n",
    "- bayes_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394da2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "belief_df = baseline_exp_df[\n",
    "    (baseline_exp_df[\"alg_id\"] == \"baposgmcp\") \n",
    "    & (baseline_exp_df[\"truncated\"] == True)\n",
    "    & (baseline_exp_df[\"action_selection\"] == \"pucb\")\n",
    "]\n",
    "\n",
    "belief_alg_ids = belief_df[\"alg_id\"].unique().tolist()\n",
    "belief_alg_ids.sort()\n",
    "print(\"Alg IDs\")\n",
    "print(\"-------\")\n",
    "for n in belief_alg_ids:\n",
    "    print(n)\n",
    "\n",
    "# group over meta-policy values\n",
    "belief_group_keys = [\"alg_id\", \"search_time_limit\"]\n",
    "belief_agg_dict = plot_utils.get_uniform_expected_agg_map(belief_df)\n",
    "belief_df_cols = set(belief_df.columns)\n",
    "keys_to_drop = []\n",
    "for k in belief_agg_dict:\n",
    "    if k not in belief_df_cols or k in belief_group_keys:\n",
    "        keys_to_drop.append(k)\n",
    "\n",
    "for k in keys_to_drop:\n",
    "    belief_agg_dict.pop(k)   \n",
    "        \n",
    "gb = belief_df.groupby(belief_group_keys)\n",
    "gb_agg = gb.agg(**belief_agg_dict)\n",
    "belief_gb_df = gb_agg.reset_index()\n",
    "\n",
    "belief_gb_df.sort_values(by=[\"search_time_limit\"], inplace=True)\n",
    "\n",
    "print(\"Ungrouped size =\", len(belief_df))\n",
    "print(\"Grouped size =\", len(belief_gb_df))\n",
    "\n",
    "display_df_info(belief_gb_df, display_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2409b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_COL_WIDTH*2, 3.7)}\n",
    "subplot_kwargs = {\n",
    "    \"xlabel\": \"Step\"\n",
    "}\n",
    "\n",
    "num_rows = 1\n",
    "num_cols = 2\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=num_rows,\n",
    "    ncols=num_cols,\n",
    "    squeeze=True,\n",
    "    subplot_kw=subplot_kwargs,\n",
    "    **fig_kwargs,\n",
    ")\n",
    "\n",
    "y_lims = [(0.05, 1.05), (-0.02, 1.7)]\n",
    "y_labels = [\"Mean Belief Probability\", \"Mean Wasserstein Distance\"]\n",
    "\n",
    "paper_utils.plot_expected_belief_stat_by_step(\n",
    "    belief_gb_df,\n",
    "    axs[0],\n",
    "    z_key=\"search_time_limit\",\n",
    "    y_key_prefix=\"bayes_accuracy\",\n",
    "    step_limit=env_info.exp_params.env_step_limit,\n",
    "    other_agent_id=1 if env_info.exp_params.planning_agent_id == 0 else 0,\n",
    "    y_suffix=\"mean\",\n",
    "    y_err_suffix=\"CI\",\n",
    ")\n",
    "axs[0].set_ylabel(y_labels[0])\n",
    "axs[0].set_ylim(y_lims[0])\n",
    "\n",
    "paper_utils.plot_expected_belief_stat_by_step(\n",
    "    belief_gb_df,\n",
    "    axs[1],\n",
    "    z_key=\"search_time_limit\",\n",
    "    y_key_prefix=\"action_dist_distance\",\n",
    "    step_limit=env_info.exp_params.env_step_limit,\n",
    "    other_agent_id=1 if env_info.exp_params.planning_agent_id == 0 else 0,\n",
    "    y_suffix=\"mean\",\n",
    "    y_err_suffix=\"CI\",\n",
    ")\n",
    "axs[1].set_ylabel(y_labels[1])\n",
    "axs[1].set_ylim(y_lims[1])\n",
    "\n",
    "handles, labels = axs[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, ncol=5, loc=\"lower center\")\n",
    "\n",
    "fig.tight_layout(rect=(0.0, 0.08, 1.0, 1.0))\n",
    "fig.savefig(osp.join(env_info.figure_dir, f\"bayes_accuracy.png\"))\n",
    "    \n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64d0c2",
   "metadata": {},
   "source": [
    "## Looking at time\n",
    "\n",
    "   - search_time\n",
    "   - update_time\n",
    "   - reinvigoration_time\n",
    "   - policy_calls\n",
    "   - inference_time\n",
    "   - search_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de76aa35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_time_df = baseline_exp_df[\n",
    "    ((baseline_exp_df[\"alg_id\"] == \"baposgmcp\") & (baseline_exp_df[\"meta_pi\"] == best_meta_pi) & (baseline_exp_df[\"truncated\"] == True))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"ucbmcp\") & (baseline_exp_df[\"meta_pi\"] == best_meta_pi) & (baseline_exp_df[\"truncated\"] == True))\n",
    "    | ((baseline_exp_df[\"alg_id\"] == \"ucbmcp-random\") & (baseline_exp_df[\"truncated\"] == False))\n",
    "]\n",
    "\n",
    "search_time_policy_prefixes_to_plot = [\n",
    "    f\"baposgmcp_meta{best_meta_pi}\",\n",
    "    \"ucbmcp-random\",\n",
    "    f\"ucbmcp_meta{best_meta_pi}\"\n",
    "]\n",
    "\n",
    "display_df_info(search_time_df, display_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f85cc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig_kwargs = {\"figsize\": (paper_utils.PAGE_COL_WIDTH, 3.8)}\n",
    "subplot_kwargs = {\n",
    "        \"xlabel\": \"Search time (s)\"\n",
    "    }\n",
    "\n",
    "\n",
    "for (y_key, y_label) in [\n",
    "    (\"episode_steps\", \"Mean episode steps\"),\n",
    "    (\"search_time\", \"Mean search time\"),\n",
    "    (\"evaluation_time\", \"Mean leaf node evaluation time\"),\n",
    "    (\"inference_time\", \"Mean inference time\"),\n",
    "    (\"update_time\", \"Mean update time\"),\n",
    "    (\"reinvigoration_time\", \"Mean belief reinvigoration time\"),\n",
    "    (\"search_depth\", \"Mean search depth\")\n",
    "]:\n",
    "    subplot_kwargs[\"ylabel\"] = y_label\n",
    "    fig, ax = plt.subplots(\n",
    "        nrows=1,\n",
    "        ncols=1,\n",
    "        squeeze=True,\n",
    "        subplot_kw=subplot_kwargs,\n",
    "        **fig_kwargs,\n",
    "    )\n",
    "        \n",
    "    paper_utils.plot_performance(\n",
    "        search_time_df,\n",
    "        ax=ax,\n",
    "        x_key=\"search_time_limit\",\n",
    "        y_key=f\"{y_key}_mean\",\n",
    "        y_err_key=f\"{y_key}_CI\",\n",
    "        policy_key=\"policy_id\",\n",
    "        policy_prefixes=search_time_policy_prefixes_to_plot,\n",
    "        constant_policy_prefixes=[],\n",
    "        pi_label_map=baseline_pi_label_map,\n",
    "    )\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, ncol=1, loc=\"lower right\")\n",
    "\n",
    "    fig.tight_layout(pad=0.1, w_pad=0.8, h_pad=1.0, rect=(0.0, 0.25, 1.0, 1.0))\n",
    "    fig.savefig(osp.join(env_info.figure_dir, f\"{y_key}.png\"))\n",
    "    \n",
    "del fig_kwargs\n",
    "del subplot_kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93473c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "potmmcp",
   "language": "python",
   "name": "potmmcp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
